# Bootcamp for Upskilling in AI Security 

Apply by June 22nd  |  Flights, accomadation, and other expenses covered  |  London, UK (In-person) | Program runs August 4th-29th 


**Primary CTA:** "Apply Now" (prominent button) **Secondary CTA:** "Learn More" (scroll down)

## the ai security bootcamp (AISB) is a 4-week long intensive program to bring researchers and engineers up to speed on security fundamentals for AI systems

# why this program?

# what will i learn? 

**Week 0: Linux Security Foundations**

- File permissions & access controls
- Process isolation & privilege management
- User/group management & sudo configuration

**Week 1: Security Fundamentals**

- **Cryptography & Cryptanalysis:** From Caesar ciphers to RSA attacks, padding oracle exploits, and timing attacks
- **Threat Modeling:** Game theory approaches, attack trees, and real-world incident analysis
- **Penetration Testing:** Full attack kill chains with Metasploit, privilege escalation, and incident response
- **Network Security:** Protocol-layer attacks (ARP spoofing, BGP hijacking, DNS poisoning), API security, and traffic analysis

**Week 2: AI Infrastructure Security**

- **Advanced Networking:** Deep-dive into network protocols and cloud security architectures
- **Containerization:** Build Docker from scratch, namespace isolation, container escape techniques
- **Supply Chain Security:** Dependency confusion attacks, typosquatting, SBOM analysis, and SolarWinds-style case studies
- **Application Security:** XSS, SQL injection, buffer overflows, SSRF, and secure coding practices
- **Security Operations:** Hands-on SecOps with misconfigured cloud environments

**Week 3: AI-Specific Security**

- **Computer Vision Attacks:** Adversarial examples, trojan injection in image models
- **LLM Vulnerabilities:** Prompt injection, system prompt extraction, RAG attacks, model attribution
- **AI Application Security:** Multi-user chatbot exploitation, DoS via expensive LLM calls, watermarking
- **AI Infrastructure:** GPU isolation attacks, RDMA vulnerabilities, ML pipeline security, cloud AI platform hardening
- **Multimodal Model Security:** Emerging attack vectors across vision-language models

**Week 4: Capstone Project**

- Choose your focus: Implement novel security solutions, replicate sophisticated attacks in controlled environments, or conduct authorized penetration testing
- Work with expert mentors on real-world security challenges
- Present findings to cohort and industry professionals

# who should apply?

our ideal candidate cares about safe and responsible development of ai systems. they also have some prior experience with deep learning (training/evals) and are comfortable with Python. 

some nice cherry-on-tops would include having a cybersecurity background, and c/c++ experience

candidates must be available to attend the program full time, in person in London


# faqs

1. what is the application process like? 

- **Fill Application Form** - Tell us about your background
- **Complete Coding Test** - Simple technical assessment
- **Interview** - Chat with our team

2. i am a high school or college student. can i still apply?

	we expect to have a mix of students as well as professionals, so you should apply if you fit the background criteria.

3. i have other commitments. can i attend this program part time? 
	the curriculum and the readings will likely not leave much time for outside commitments, so we would recommend not having other major time commitments during the bootcamp. 
	
	feel free to [reach out](mailto:pranav@aisb.dev) if you'd like to discuss your specific circumstances.

4. what are the recommended prerequisites?

	We recommend having a solid background in deep learning (or completing a program like MLAB or ARENA) and being comfortable with Python. These skills will help you make the most of the hands-on exercises and technical content during the bootcamp. We'll also send preparatory materials a couple of weeks before the program to help you brush up on essentials.

5. can i join this program for some weeks but not others?
	No, given we have limited spaces, we would be more excited to have participants who can commit to the entire four weeks of the program.

6. what will an average day look like?
	You'll start the day with a lecture or a deep dive into a significant vulnerability or exploit. After this, you will spend most of your time pair programming to work on the exercises, and reading relevant material. We will plan to wrap up the exercises by dinnertime, after which we'll have some additional reading material to prepare for the next day.
	
	In the last week, you'll work on a capstone project with a mentor - this can be implementing a security solution, replicating a significant cyberattack (in a controlled environment), or trying to break into systems (again, with explicit permission)
7. does this program cost money?
	nope. in fact, we will also take care of accommodation, travel, food (lunch/dinner on weekdays), and visas if needed. 


# meet the team
### **Jan Michelfeit**

Security lead at Conjecture. Designs AISBâ€™s hands-on labs and capstone projects, drawing on 10+ years securing complex systems and ML infrastructure.

### **Pranav Gade**

Research engineer at Conjecture. Created AISB to bridge AI safety and security, and leads curriculum design and program direction.

### **Jinglin Li**

Engineer and educator. Keeps AISB running smoothly while supporting participants and building tools for capstone research.
website inspo
- https://www.sfparc.com/
- interaction.co/about
- 